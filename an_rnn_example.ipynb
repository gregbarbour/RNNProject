{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.layers import BatchNormalization, Layer, TimeDistributed, Dropout\n",
    "from keras.layers import Dense, Input, Masking, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by trying to load in our toy jets, and then separate into features (to train on) and labels (to predict).\n",
    "\n",
    "For features, first try d0, z0, phi, theta, qOverP, (refPx, refPy, refPz)?. Essentially the track parameters.\n",
    "\n",
    "For labels, Xs, Ys, Zs, Xt, Yt, Zt. That is the secondary and tertiary vertices. Omit the primary as this has been fixed to (0,0,0). This will require some smart selection for c and light jets, where not all vertices are present. If a vertex is not present, could try predicting (0,0,0) or (-1,-1,-1) or previous vertex (prim or sec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjets_DF = pd.read_pickle(\"./bjets_reverse_prims_jetKinTrack.pkl\")\n",
    "#cjets_DF = pd.read_pickle(\"./cjets.pkl\")\n",
    "#ljets_DF = pd.read_pickle(\"./ljets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.64618812e-03, 1.61855932e-03, 3.24006061e-03,\n",
       "        3.26463501e-03, 3.24387692e-03, 1.08122496e-05, 1.08997629e-05,\n",
       "                   nan,            nan,            nan,            nan,\n",
       "                   nan,            nan,            nan,            nan,\n",
       "                   nan,            nan,            nan,            nan,\n",
       "                   nan,            nan,            nan,            nan,\n",
       "                   nan,            nan,            nan,            nan,\n",
       "                   nan,            nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([bjets_DF['tracks'][0]])[:,:,5:8], axis=2) #gives a feel for ordering, lists r of ref postion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the track parameters as our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trks=np.zeros((len(bjets_DF), 30, 5))\n",
    "\n",
    "for i in range(len(bjets_DF)):\n",
    "    trks[i] = np.array([bjets_DF['tracks'][i]])[:,:,0:5]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trks # following convention name the features as the vector 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling: Change 1/p to p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try changing the 1/p feature to p, see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " No Change to end accuracy nor speed-up so won't do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4850.46696803,  3060.74292196,  4054.83541082, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [ 2050.96833157,  5200.69668043,  1918.47163884, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [ 3774.24046227, 14472.05631949,  2894.37128725, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [ 2883.77907606,  5114.71929641,  2072.69149129, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [ 2566.318433  ,   620.46562403,   563.21545658, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [ 4284.22553045,  7638.42365794,  1493.57056224, ...,\n",
       "                   nan,            nan,            nan]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1/X[:,:,4]  # these are individual tracks remember so p<10,000 is allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[:,:,4] = 1/X[:,:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use numpy sort function should work, order in descending value say of impact parameter or something (shouldnt be any negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe want to move this section and order later, after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we want to ensure all paramters are approx unity in order not to bias the RNN towards a particular feature. phi and theta are already approx unity (order pi), but qOverP is very small order 1e-4 and IP are also small (but scale multiple orders of magnitude) 1e-6 to 1e-2 (unfortunately)\n",
    "\n",
    "So want to use a min max scaler or RobustScaler (so we don't bias to outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:391: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (a >= first_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:392: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (a <= last_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.324267e+06, 2.710900e+05, 6.057000e+04, ..., 0.000000e+00,\n",
       "        0.000000e+00, 1.000000e+00]),\n",
       " array([0.00000000e+00, 1.60159944e-05, 3.20319889e-05, ...,\n",
       "        3.08788373e-02, 3.08948533e-02, 3.09108692e-02]),\n",
       " <a list of 1930 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d0s = np.reshape(X[:,:,0],(30*len(bjets_DF)))\n",
    "d0s = d0s[~(d0s == np.NaN)]\n",
    "d0s\n",
    "plt.hist(d0s,bins='scott') # I believe this is the array containing all the d0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X[:,:,0]*1e4))\n",
    "print(np.mean(X[:,:,1]*1e6)) # difficult one to handle this due to large variance\n",
    "print(np.mean(X[:,:,4]*1e4))\n",
    "print()\n",
    "print(np.std(X[:,:,0]*1e4)) # these are troublesome yes\n",
    "print(np.std(X[:,:,1]*1e6))\n",
    "print(np.std(X[:,:,4]*1e4))\n",
    "# so we will apply the above multiples, this will bring the averages to about unity (unfortunately some outliers will\n",
    "# be very large, so probs better to use a min max scaler or something but then exclude 0?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we scale all the features to bring them to average unity, this is very simplistic so we need a better way in future\n",
    "\n",
    "It means it works faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T USE, achieve better scaling below with\n",
    "firsttime=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if firsttime==True:\n",
    "    Xsimpscal=copy.copy(X)\n",
    "    Xsimpscal[:,:,0]=X[:,:,0]*1e4\n",
    "    Xsimpscal[:,:,1]=X[:,:,1]*1e6\n",
    "    Xsimpscal[:,:,4]=X[:,:,4]*1e4\n",
    "    firsttime = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instead use a min-max scaler to try and solve the problem of scale i.e. certain IPs are 10^4 times larger than others. The min-max scaler means all features will be scaled equivalently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go, minmax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled = copy.copy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:355: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:356: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:355: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:356: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:959: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for track_variable in range(5):\n",
    "    var_to_scale = Xscaled[:,:,track_variable]\n",
    "    if (track_variable == 0):\n",
    "        print((track_variable == 0))\n",
    "        print(track_variable)\n",
    "        scaler=RobustScaler()\n",
    "    elif (track_variable == 4):\n",
    "        print((track_variable == 4))\n",
    "        print(track_variable)\n",
    "        scaler=RobustScaler()\n",
    "    elif (track_variable == 1):\n",
    "        print(track_variable)\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        scaler=MinMaxScaler([-1,1])\n",
    "    scaler.fit(var_to_scale)\n",
    "    Xscaled[:,:,track_variable] = scaler.transform(var_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:391: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (a >= first_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:392: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (a <= last_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "C:\\Users\\Greg\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var=4\n",
    "trackvar = X[:,:,var]\n",
    "trackvar = trackvar[~(trackvar == np.NaN)]\n",
    "print(len(trackvar))\n",
    "\n",
    "plt.hist(trackvar,bins='scott',log=True)\n",
    "plt.show()\n",
    "\n",
    "trackvar2 = Xscaled[:,:,var]\n",
    "trackvar2 = trackvar2[~(trackvar2 == np.NaN)]\n",
    "print(len(trackvar2))\n",
    "\n",
    "\n",
    "plt.hist(trackvar2,bins='scott',log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled = np.nan_to_num(Xscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we scale the outputs, actually more simple, we change units from metres to millimetres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the secondary and tertiary vertices as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bjets_DF[['secVtx_x','secVtx_y','secVtx_z','terVtx_x','terVtx_y','terVtx_z']].values \n",
    "y = y*1000 # change units of vertices from m to mm, keep vals close to unity # come back change GREGG!!!\n",
    "# again convention call labels 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split first 80000 jets as train and next 20000 as test. Below some plots to show these jets are equivalently distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280000\n"
     ]
    }
   ],
   "source": [
    "split= 280000 #int(0.9*len(bjets_DF))\n",
    "X_train=Xscaled[:split]\n",
    "X_test=Xscaled[split:]\n",
    "y_train=y[:split]\n",
    "y_test=y[split:]\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_s1=np.linalg.norm(bjets_DF[['secVtx_x','secVtx_y','secVtx_z']],axis=1)[:split]\n",
    "b_s2=np.linalg.norm(bjets_DF[['secVtx_x','secVtx_y','secVtx_z']],axis=1)[split:]\n",
    "b_t1=np.linalg.norm(bjets_DF[['terVtx_x','terVtx_y','terVtx_z']],axis=1)[:split]\n",
    "b_t2=np.linalg.norm(bjets_DF[['terVtx_x','terVtx_y','terVtx_z']],axis=1)[split:]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0036881077136951806\n",
      "0.007020509848532561\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_s1,bins='scott',range=[0,0.01])\n",
    "#plt.hist(c_SecVtx,bins='scott',range=[0,0.01])\n",
    "plt.hist(b_t1,bins='scott',range=[0,0.01])\n",
    "\n",
    "print(np.mean(b_s1))\n",
    "print(np.mean(b_t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0036867697567230765\n",
      "0.0069798565303123665\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_s2,bins='scott',range=[0,0.01])\n",
    "#plt.hist(c_SecVtx,bins='scott',range=[0,0.01])\n",
    "plt.hist(b_t2,bins='scott',range=[0,0.01])\n",
    "\n",
    "print(np.mean(b_s2))\n",
    "print(np.mean(b_t2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have our features, X, and labels, y. Split into training and testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Plots and Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I should have some plots on the track variables to ensure everything is logical and working fine, especially when I make changes to the data. Can potentially use seaborn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing and Training an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create an RNN based on LSTM cells using keras and tensorflow. The RNN will for each jet candidate take the tracks as inputs and attempt to predict the secondary and tertiary vertex positions. Let's see how well it does.\n",
    "\n",
    "I anticipate having to set a tolerance on the predicted values, it will never get them perfectly but we need to tell it how close it has to get for it to be considered successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by creating the RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of hidden and dense layers. Initially use same as RNNIP but these can be tuned going forward.\n",
    "\n",
    "nHidden = 100\n",
    "nDense = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nJets, nTrks, nFeatures = X_train.shape\n",
    "nOutputs = y.shape[1] # ie sec and ter vtx xyz, so 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_inputs = Input(shape=(nTrks,nFeatures),name=\"Trk_inputs\")\n",
    "masked_input = Masking()(trk_inputs)\n",
    "\n",
    "# Feed this merged layer to an RNN\n",
    "lstm = LSTM(nHidden, return_sequences=False, name='LSTM')(masked_input)\n",
    "dpt = Dropout(rate=0.2)(lstm) # this is a very high dropout rate, reduce it\n",
    "\n",
    "my_inputs = trk_inputs\n",
    "\n",
    "# Fully connected layer: This will convert the output of the RNN to our vtx postion predicitons\n",
    "FC = Dense(nDense, activation='relu', name=\"Dense\")(dpt) # is relu fine here? i think so...\n",
    "\n",
    "# Ouptut layer. Sec and Ter Vtx. No activation as this is a regression problem\n",
    "output = Dense(nOutputs, name=\"Vertex_Predictions\")(FC)\n",
    "\n",
    "myRNN = Model(inputs=my_inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Trk_inputs (InputLayer)      (None, 30, 5)             0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 30, 5)             0         \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 100)               42400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "Vertex_Predictions (Dense)   (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 44,546\n",
      "Trainable params: 44,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRNN.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae']) # do i want to add a metric like mse to evaluate during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " checkpoints, training, evaluation of performance\n",
    " different ways of evaluating performance obviously\n",
    " either akin to Nicole's method for RNNIP\n",
    " or the slighlty different method in https://github.com/agu3rra/NeuralNetwork-RegressionExample/blob/master/Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRNN_mChkPt = ModelCheckpoint('myRNN_weights.h5',monitor='val_loss', verbose=True,\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', verbose=True, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224000 samples, validate on 56000 samples\n",
      "Epoch 1/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 1.1914 - mean_absolute_error: 1.1914Epoch 00001: val_loss improved from inf to 0.87157, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 68s 304us/step - loss: 1.1911 - mean_absolute_error: 1.1911 - val_loss: 0.8716 - val_mean_absolute_error: 0.8716\n",
      "Epoch 2/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.8606 - mean_absolute_error: 0.8606Epoch 00002: val_loss improved from 0.87157 to 0.79249, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 72s 323us/step - loss: 0.8606 - mean_absolute_error: 0.8606 - val_loss: 0.7925 - val_mean_absolute_error: 0.7925\n",
      "Epoch 3/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.8076 - mean_absolute_error: 0.8076Epoch 00003: val_loss improved from 0.79249 to 0.76333, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 70s 311us/step - loss: 0.8075 - mean_absolute_error: 0.8075 - val_loss: 0.7633 - val_mean_absolute_error: 0.7633\n",
      "Epoch 4/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.7782 - mean_absolute_error: 0.7782Epoch 00004: val_loss improved from 0.76333 to 0.72294, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 77s 342us/step - loss: 0.7781 - mean_absolute_error: 0.7781 - val_loss: 0.7229 - val_mean_absolute_error: 0.7229\n",
      "Epoch 5/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.7556 - mean_absolute_error: 0.7556Epoch 00005: val_loss improved from 0.72294 to 0.70416, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 80s 359us/step - loss: 0.7557 - mean_absolute_error: 0.7557 - val_loss: 0.7042 - val_mean_absolute_error: 0.7042\n",
      "Epoch 6/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.7375 - mean_absolute_error: 0.7375Epoch 00006: val_loss improved from 0.70416 to 0.69184, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 84s 374us/step - loss: 0.7376 - mean_absolute_error: 0.7376 - val_loss: 0.6918 - val_mean_absolute_error: 0.6918\n",
      "Epoch 7/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.7208 - mean_absolute_error: 0.7208Epoch 00007: val_loss improved from 0.69184 to 0.67299, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 81s 361us/step - loss: 0.7207 - mean_absolute_error: 0.7207 - val_loss: 0.6730 - val_mean_absolute_error: 0.6730\n",
      "Epoch 8/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.7023 - mean_absolute_error: 0.7023Epoch 00008: val_loss improved from 0.67299 to 0.64622, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 352us/step - loss: 0.7022 - mean_absolute_error: 0.7022 - val_loss: 0.6462 - val_mean_absolute_error: 0.6462\n",
      "Epoch 9/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.6799 - mean_absolute_error: 0.6799Epoch 00009: val_loss improved from 0.64622 to 0.61873, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 366us/step - loss: 0.6798 - mean_absolute_error: 0.6798 - val_loss: 0.6187 - val_mean_absolute_error: 0.6187\n",
      "Epoch 10/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.6542 - mean_absolute_error: 0.6542Epoch 00010: val_loss improved from 0.61873 to 0.59145, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 366us/step - loss: 0.6542 - mean_absolute_error: 0.6542 - val_loss: 0.5914 - val_mean_absolute_error: 0.5914\n",
      "Epoch 11/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.6313 - mean_absolute_error: 0.6313Epoch 00011: val_loss improved from 0.59145 to 0.56878, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 81s 359us/step - loss: 0.6313 - mean_absolute_error: 0.6313 - val_loss: 0.5688 - val_mean_absolute_error: 0.5688\n",
      "Epoch 12/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.6157 - mean_absolute_error: 0.6157Epoch 00012: val_loss improved from 0.56878 to 0.55232, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 80s 356us/step - loss: 0.6156 - mean_absolute_error: 0.6156 - val_loss: 0.5523 - val_mean_absolute_error: 0.5523\n",
      "Epoch 13/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.6008 - mean_absolute_error: 0.6008Epoch 00013: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 355us/step - loss: 0.6008 - mean_absolute_error: 0.6008 - val_loss: 0.5533 - val_mean_absolute_error: 0.5533\n",
      "Epoch 14/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5895 - mean_absolute_error: 0.5895Epoch 00014: val_loss improved from 0.55232 to 0.53067, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.5894 - mean_absolute_error: 0.5894 - val_loss: 0.5307 - val_mean_absolute_error: 0.5307\n",
      "Epoch 15/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5783 - mean_absolute_error: 0.5783Epoch 00015: val_loss improved from 0.53067 to 0.51772, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.5782 - mean_absolute_error: 0.5782 - val_loss: 0.5177 - val_mean_absolute_error: 0.5177\n",
      "Epoch 16/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5702 - mean_absolute_error: 0.5702- ETA: 3s - loss:Epoch 00016: val_loss improved from 0.51772 to 0.51646, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 348us/step - loss: 0.5702 - mean_absolute_error: 0.5702 - val_loss: 0.5165 - val_mean_absolute_error: 0.5165\n",
      "Epoch 17/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5627 - mean_absolute_error: 0.5627Epoch 00017: val_loss improved from 0.51646 to 0.50455, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 77s 343us/step - loss: 0.5627 - mean_absolute_error: 0.5627 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045\n",
      "Epoch 18/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5561 - mean_absolute_error: 0.5561Epoch 00018: val_loss improved from 0.50455 to 0.50385, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 77s 343us/step - loss: 0.5560 - mean_absolute_error: 0.5560 - val_loss: 0.5038 - val_mean_absolute_error: 0.5038\n",
      "Epoch 19/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5498 - mean_absolute_error: 0.5498- ETA: 1s - loss: 0.5499 - mean_absoluteEpoch 00019: val_loss improved from 0.50385 to 0.49504, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.5499 - mean_absolute_error: 0.5499 - val_loss: 0.4950 - val_mean_absolute_error: 0.4950\n",
      "Epoch 20/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5437 - mean_absolute_error: 0.5437Epoch 00020: val_loss improved from 0.49504 to 0.47896, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 76s 338us/step - loss: 0.5438 - mean_absolute_error: 0.5438 - val_loss: 0.4790 - val_mean_absolute_error: 0.4790\n",
      "Epoch 21/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5377 - mean_absolute_error: 0.5377Epoch 00021: val_loss improved from 0.47896 to 0.47836, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 367us/step - loss: 0.5378 - mean_absolute_error: 0.5378 - val_loss: 0.4784 - val_mean_absolute_error: 0.4784\n",
      "Epoch 22/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5329 - mean_absolute_error: 0.5329Epoch 00022: val_loss improved from 0.47836 to 0.47049, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 348us/step - loss: 0.5329 - mean_absolute_error: 0.5329 - val_loss: 0.4705 - val_mean_absolute_error: 0.4705\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5284 - mean_absolute_error: 0.5284Epoch 00023: val_loss improved from 0.47049 to 0.46861, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 348us/step - loss: 0.5285 - mean_absolute_error: 0.5285 - val_loss: 0.4686 - val_mean_absolute_error: 0.4686\n",
      "Epoch 24/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5237 - mean_absolute_error: 0.5237Epoch 00024: val_loss improved from 0.46861 to 0.46455, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 75s 335us/step - loss: 0.5236 - mean_absolute_error: 0.5236 - val_loss: 0.4645 - val_mean_absolute_error: 0.4645\n",
      "Epoch 25/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5191 - mean_absolute_error: 0.5191Epoch 00025: val_loss improved from 0.46455 to 0.46268, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 75s 337us/step - loss: 0.5190 - mean_absolute_error: 0.5190 - val_loss: 0.4627 - val_mean_absolute_error: 0.4627\n",
      "Epoch 26/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5148 - mean_absolute_error: 0.5148Epoch 00026: val_loss improved from 0.46268 to 0.45393, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 91s 406us/step - loss: 0.5147 - mean_absolute_error: 0.5147 - val_loss: 0.4539 - val_mean_absolute_error: 0.4539\n",
      "Epoch 27/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5105 - mean_absolute_error: 0.5105Epoch 00027: val_loss improved from 0.45393 to 0.44875, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 353us/step - loss: 0.5104 - mean_absolute_error: 0.5104 - val_loss: 0.4487 - val_mean_absolute_error: 0.4487\n",
      "Epoch 28/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5064 - mean_absolute_error: 0.5064Epoch 00028: val_loss did not improve\n",
      "224000/224000 [==============================] - 84s 376us/step - loss: 0.5064 - mean_absolute_error: 0.5064 - val_loss: 0.4524 - val_mean_absolute_error: 0.4524\n",
      "Epoch 29/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.5007 - mean_absolute_error: 0.5007Epoch 00029: val_loss improved from 0.44875 to 0.44637, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 84s 377us/step - loss: 0.5006 - mean_absolute_error: 0.5006 - val_loss: 0.4464 - val_mean_absolute_error: 0.4464\n",
      "Epoch 30/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4978 - mean_absolute_error: 0.4978Epoch 00030: val_loss improved from 0.44637 to 0.43591, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 76s 341us/step - loss: 0.4978 - mean_absolute_error: 0.4978 - val_loss: 0.4359 - val_mean_absolute_error: 0.4359\n",
      "Epoch 31/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4931 - mean_absolute_error: 0.4931Epoch 00031: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 353us/step - loss: 0.4931 - mean_absolute_error: 0.4931 - val_loss: 0.4383 - val_mean_absolute_error: 0.4383\n",
      "Epoch 32/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4889 - mean_absolute_error: 0.4889Epoch 00032: val_loss improved from 0.43591 to 0.42788, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 367us/step - loss: 0.4889 - mean_absolute_error: 0.4889 - val_loss: 0.4279 - val_mean_absolute_error: 0.4279\n",
      "Epoch 33/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4840 - mean_absolute_error: 0.4840- ETA: 3s - loss: 0.4837 - mean_a - ETA: 2s - loss: 0.4838 - mea - ETA: 0s - loss: 0.4840 - mean_absolute_error: 0.484Epoch 00033: val_loss improved from 0.42788 to 0.42121, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 366us/step - loss: 0.4840 - mean_absolute_error: 0.4840 - val_loss: 0.4212 - val_mean_absolute_error: 0.4212\n",
      "Epoch 34/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4797 - mean_absolute_error: 0.4797  ETA: 11s - lo - ETA: 8s - l - ETA: 5s - - ETA: 1s - loss: 0.4799 - mean_aEpoch 00034: val_loss did not improve\n",
      "224000/224000 [==============================] - 80s 357us/step - loss: 0.4798 - mean_absolute_error: 0.4798 - val_loss: 0.4212 - val_mean_absolute_error: 0.4212\n",
      "Epoch 35/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4768 - mean_absolute_error: 0.4768Epoch 00035: val_loss improved from 0.42121 to 0.42077, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 349us/step - loss: 0.4767 - mean_absolute_error: 0.4767 - val_loss: 0.4208 - val_mean_absolute_error: 0.4208\n",
      "Epoch 36/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4723 - mean_absolute_error: 0.4723Epoch 00036: val_loss improved from 0.42077 to 0.41590, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 82s 368us/step - loss: 0.4723 - mean_absolute_error: 0.4723 - val_loss: 0.4159 - val_mean_absolute_error: 0.4159\n",
      "Epoch 37/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4688 - mean_absolute_error: 0.4688Epoch 00037: val_loss improved from 0.41590 to 0.40962, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 354us/step - loss: 0.4689 - mean_absolute_error: 0.4689 - val_loss: 0.4096 - val_mean_absolute_error: 0.4096\n",
      "Epoch 38/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4660 - mean_absolute_error: 0.4660Epoch 00038: val_loss improved from 0.40962 to 0.40866, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 351us/step - loss: 0.4660 - mean_absolute_error: 0.4660 - val_loss: 0.4087 - val_mean_absolute_error: 0.4087\n",
      "Epoch 39/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4630 - mean_absolute_error: 0.4630Epoch 00039: val_loss did not improve\n",
      "224000/224000 [==============================] - 81s 361us/step - loss: 0.4630 - mean_absolute_error: 0.4630 - val_loss: 0.4095 - val_mean_absolute_error: 0.4095\n",
      "Epoch 40/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4599 - mean_absolute_error: 0.4599Epoch 00040: val_loss improved from 0.40866 to 0.40595, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 80s 359us/step - loss: 0.4599 - mean_absolute_error: 0.4599 - val_loss: 0.4060 - val_mean_absolute_error: 0.4060\n",
      "Epoch 41/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4568 - mean_absolute_error: 0.4568Epoch 00041: val_loss improved from 0.40595 to 0.40138, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 348us/step - loss: 0.4569 - mean_absolute_error: 0.4569 - val_loss: 0.4014 - val_mean_absolute_error: 0.4014\n",
      "Epoch 42/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4540 - mean_absolute_error: 0.4540Epoch 00042: val_loss improved from 0.40138 to 0.39028, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 80s 359us/step - loss: 0.4540 - mean_absolute_error: 0.4540 - val_loss: 0.3903 - val_mean_absolute_error: 0.3903\n",
      "Epoch 43/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4511 - mean_absolute_error: 0.4511Epoch 00043: val_loss improved from 0.39028 to 0.38634, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 351us/step - loss: 0.4511 - mean_absolute_error: 0.4511 - val_loss: 0.3863 - val_mean_absolute_error: 0.3863\n",
      "Epoch 44/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4482 - mean_absolute_error: 0.4482Epoch 00044: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 351us/step - loss: 0.4482 - mean_absolute_error: 0.4482 - val_loss: 0.3886 - val_mean_absolute_error: 0.3886\n",
      "Epoch 45/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4466 - mean_absolute_error: 0.4466Epoch 00045: val_loss did not improve\n",
      "224000/224000 [==============================] - 80s 356us/step - loss: 0.4466 - mean_absolute_error: 0.4466 - val_loss: 0.3912 - val_mean_absolute_error: 0.3912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4435 - mean_absolute_error: 0.4435Epoch 00046: val_loss improved from 0.38634 to 0.38477, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 75s 335us/step - loss: 0.4436 - mean_absolute_error: 0.4436 - val_loss: 0.3848 - val_mean_absolute_error: 0.3848\n",
      "Epoch 47/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4416 - mean_absolute_error: 0.4416Epoch 00047: val_loss improved from 0.38477 to 0.37851, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 354us/step - loss: 0.4416 - mean_absolute_error: 0.4416 - val_loss: 0.3785 - val_mean_absolute_error: 0.3785\n",
      "Epoch 48/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4382 - mean_absolute_error: 0.4382- ETA: 0s - loss: 0.4381 - mean_absolute_error: 0.Epoch 00048: val_loss did not improve\n",
      "224000/224000 [==============================] - 77s 345us/step - loss: 0.4382 - mean_absolute_error: 0.4382 - val_loss: 0.3832 - val_mean_absolute_error: 0.3832\n",
      "Epoch 49/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4356 - mean_absolute_error: 0.4356Epoch 00049: val_loss did not improve\n",
      "224000/224000 [==============================] - 77s 344us/step - loss: 0.4355 - mean_absolute_error: 0.4355 - val_loss: 0.3837 - val_mean_absolute_error: 0.3837\n",
      "Epoch 50/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4336 - mean_absolute_error: 0.4336Epoch 00050: val_loss did not improve\n",
      "224000/224000 [==============================] - 76s 337us/step - loss: 0.4336 - mean_absolute_error: 0.4336 - val_loss: 0.3846 - val_mean_absolute_error: 0.3846\n",
      "Epoch 51/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4314 - mean_absolute_error: 0.4314Epoch 00051: val_loss improved from 0.37851 to 0.37784, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.4314 - mean_absolute_error: 0.4314 - val_loss: 0.3778 - val_mean_absolute_error: 0.3778\n",
      "Epoch 52/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4300 - mean_absolute_error: 0.4300Epoch 00052: val_loss improved from 0.37784 to 0.37323, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 76s 338us/step - loss: 0.4300 - mean_absolute_error: 0.4300 - val_loss: 0.3732 - val_mean_absolute_error: 0.3732\n",
      "Epoch 53/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4267 - mean_absolute_error: 0.4267Epoch 00053: val_loss improved from 0.37323 to 0.36861, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 77s 345us/step - loss: 0.4268 - mean_absolute_error: 0.4268 - val_loss: 0.3686 - val_mean_absolute_error: 0.3686\n",
      "Epoch 54/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4260 - mean_absolute_error: 0.4260Epoch 00054: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 336us/step - loss: 0.4260 - mean_absolute_error: 0.4260 - val_loss: 0.3710 - val_mean_absolute_error: 0.3710\n",
      "Epoch 55/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4238 - mean_absolute_error: 0.4238Epoch 00055: val_loss improved from 0.36861 to 0.36724, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 76s 340us/step - loss: 0.4238 - mean_absolute_error: 0.4238 - val_loss: 0.3672 - val_mean_absolute_error: 0.3672\n",
      "Epoch 56/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4208 - mean_absolute_error: 0.4208Epoch 00056: val_loss improved from 0.36724 to 0.35999, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 73s 327us/step - loss: 0.4208 - mean_absolute_error: 0.4208 - val_loss: 0.3600 - val_mean_absolute_error: 0.3600\n",
      "Epoch 57/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4196 - mean_absolute_error: 0.4196Epoch 00057: val_loss did not improve\n",
      "224000/224000 [==============================] - 74s 329us/step - loss: 0.4196 - mean_absolute_error: 0.4196 - val_loss: 0.3685 - val_mean_absolute_error: 0.3685\n",
      "Epoch 58/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4167 - mean_absolute_error: 0.4167Epoch 00058: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 337us/step - loss: 0.4166 - mean_absolute_error: 0.4166 - val_loss: 0.3756 - val_mean_absolute_error: 0.3756\n",
      "Epoch 59/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4152 - mean_absolute_error: 0.4152Epoch 00059: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 333us/step - loss: 0.4153 - mean_absolute_error: 0.4153 - val_loss: 0.3608 - val_mean_absolute_error: 0.3608\n",
      "Epoch 60/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4132 - mean_absolute_error: 0.4132Epoch 00060: val_loss did not improve\n",
      "224000/224000 [==============================] - 73s 328us/step - loss: 0.4132 - mean_absolute_error: 0.4132 - val_loss: 0.3635 - val_mean_absolute_error: 0.3635\n",
      "Epoch 61/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4108 - mean_absolute_error: 0.4108Epoch 00061: val_loss improved from 0.35999 to 0.35574, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 75s 335us/step - loss: 0.4108 - mean_absolute_error: 0.4108 - val_loss: 0.3557 - val_mean_absolute_error: 0.3557\n",
      "Epoch 62/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4101 - mean_absolute_error: 0.4101Epoch 00062: val_loss did not improve\n",
      "224000/224000 [==============================] - 74s 330us/step - loss: 0.4101 - mean_absolute_error: 0.4101 - val_loss: 0.3629 - val_mean_absolute_error: 0.3629\n",
      "Epoch 63/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4080 - mean_absolute_error: 0.4080Epoch 00063: val_loss improved from 0.35574 to 0.35397, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 75s 333us/step - loss: 0.4079 - mean_absolute_error: 0.4079 - val_loss: 0.3540 - val_mean_absolute_error: 0.3540\n",
      "Epoch 64/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4063 - mean_absolute_error: 0.4063Epoch 00064: val_loss did not improve\n",
      "224000/224000 [==============================] - 73s 326us/step - loss: 0.4064 - mean_absolute_error: 0.4064 - val_loss: 0.3553 - val_mean_absolute_error: 0.3553\n",
      "Epoch 65/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4050 - mean_absolute_error: 0.4050Epoch 00065: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 335us/step - loss: 0.4050 - mean_absolute_error: 0.4050 - val_loss: 0.3632 - val_mean_absolute_error: 0.3632\n",
      "Epoch 66/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4032 - mean_absolute_error: 0.4032Epoch 00066: val_loss did not improve\n",
      "224000/224000 [==============================] - 73s 327us/step - loss: 0.4031 - mean_absolute_error: 0.4031 - val_loss: 0.3591 - val_mean_absolute_error: 0.3591\n",
      "Epoch 67/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4032 - mean_absolute_error: 0.4032Epoch 00067: val_loss did not improve\n",
      "224000/224000 [==============================] - 74s 330us/step - loss: 0.4032 - mean_absolute_error: 0.4032 - val_loss: 0.3545 - val_mean_absolute_error: 0.3545\n",
      "Epoch 68/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.4002 - mean_absolute_error: 0.4002Epoch 00068: val_loss did not improve\n",
      "224000/224000 [==============================] - 74s 330us/step - loss: 0.4001 - mean_absolute_error: 0.4001 - val_loss: 0.3609 - val_mean_absolute_error: 0.3609\n",
      "Epoch 69/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3995 - mean_absolute_error: 0.3995Epoch 00069: val_loss improved from 0.35397 to 0.35252, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 74s 331us/step - loss: 0.3995 - mean_absolute_error: 0.3995 - val_loss: 0.3525 - val_mean_absolute_error: 0.3525\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3976 - mean_absolute_error: 0.3976Epoch 00070: val_loss improved from 0.35252 to 0.34544, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 74s 328us/step - loss: 0.3976 - mean_absolute_error: 0.3976 - val_loss: 0.3454 - val_mean_absolute_error: 0.3454\n",
      "Epoch 71/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3966 - mean_absolute_error: 0.3966Epoch 00071: val_loss did not improve\n",
      "224000/224000 [==============================] - 73s 328us/step - loss: 0.3966 - mean_absolute_error: 0.3966 - val_loss: 0.3515 - val_mean_absolute_error: 0.3515\n",
      "Epoch 72/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3943 - mean_absolute_error: 0.3943Epoch 00072: val_loss did not improve\n",
      "224000/224000 [==============================] - 74s 332us/step - loss: 0.3943 - mean_absolute_error: 0.3943 - val_loss: 0.3506 - val_mean_absolute_error: 0.3506\n",
      "Epoch 73/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3932 - mean_absolute_error: 0.3932Epoch 00073: val_loss improved from 0.34544 to 0.34522, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 74s 330us/step - loss: 0.3932 - mean_absolute_error: 0.3932 - val_loss: 0.3452 - val_mean_absolute_error: 0.3452\n",
      "Epoch 74/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3934 - mean_absolute_error: 0.3934Epoch 00074: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 333us/step - loss: 0.3933 - mean_absolute_error: 0.3933 - val_loss: 0.3571 - val_mean_absolute_error: 0.3571\n",
      "Epoch 75/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3906 - mean_absolute_error: 0.3906Epoch 00075: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 336us/step - loss: 0.3906 - mean_absolute_error: 0.3906 - val_loss: 0.3503 - val_mean_absolute_error: 0.3503\n",
      "Epoch 76/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3897 - mean_absolute_error: 0.3897- ETA: 2s - loss: 0.3896Epoch 00076: val_loss improved from 0.34522 to 0.34308, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 348us/step - loss: 0.3897 - mean_absolute_error: 0.3897 - val_loss: 0.3431 - val_mean_absolute_error: 0.3431\n",
      "Epoch 77/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3886 - mean_absolute_error: 0.3886Epoch 00077: val_loss did not improve\n",
      "224000/224000 [==============================] - 75s 333us/step - loss: 0.3886 - mean_absolute_error: 0.3886 - val_loss: 0.3506 - val_mean_absolute_error: 0.3506\n",
      "Epoch 78/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3866 - mean_absolute_error: 0.3866Epoch 00078: val_loss did not improve\n",
      "224000/224000 [==============================] - 77s 342us/step - loss: 0.3866 - mean_absolute_error: 0.3866 - val_loss: 0.3443 - val_mean_absolute_error: 0.3443\n",
      "Epoch 79/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3858 - mean_absolute_error: 0.3858Epoch 00079: val_loss improved from 0.34308 to 0.33823, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 354us/step - loss: 0.3858 - mean_absolute_error: 0.3858 - val_loss: 0.3382 - val_mean_absolute_error: 0.3382\n",
      "Epoch 80/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3854 - mean_absolute_error: 0.3854Epoch 00080: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.3855 - mean_absolute_error: 0.3855 - val_loss: 0.3443 - val_mean_absolute_error: 0.3443\n",
      "Epoch 81/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3843 - mean_absolute_error: 0.3843Epoch 00081: val_loss did not improve\n",
      "224000/224000 [==============================] - 76s 339us/step - loss: 0.3843 - mean_absolute_error: 0.3843 - val_loss: 0.3416 - val_mean_absolute_error: 0.3416\n",
      "Epoch 82/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3842 - mean_absolute_error: 0.3842Epoch 00082: val_loss improved from 0.33823 to 0.33696, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 77s 342us/step - loss: 0.3841 - mean_absolute_error: 0.3841 - val_loss: 0.3370 - val_mean_absolute_error: 0.3370\n",
      "Epoch 83/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3824 - mean_absolute_error: 0.3824Epoch 00083: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 353us/step - loss: 0.3825 - mean_absolute_error: 0.3825 - val_loss: 0.3373 - val_mean_absolute_error: 0.3373\n",
      "Epoch 84/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3810 - mean_absolute_error: 0.3810Epoch 00084: val_loss improved from 0.33696 to 0.33660, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 76s 341us/step - loss: 0.3811 - mean_absolute_error: 0.3811 - val_loss: 0.3366 - val_mean_absolute_error: 0.3366\n",
      "Epoch 85/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3800 - mean_absolute_error: 0.3800Epoch 00085: val_loss did not improve\n",
      "224000/224000 [==============================] - 77s 345us/step - loss: 0.3800 - mean_absolute_error: 0.3800 - val_loss: 0.3408 - val_mean_absolute_error: 0.3408\n",
      "Epoch 86/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3783 - mean_absolute_error: 0.3783Epoch 00086: val_loss improved from 0.33660 to 0.33450, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 354us/step - loss: 0.3783 - mean_absolute_error: 0.3783 - val_loss: 0.3345 - val_mean_absolute_error: 0.3345\n",
      "Epoch 87/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3780 - mean_absolute_error: 0.3780Epoch 00087: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 347us/step - loss: 0.3780 - mean_absolute_error: 0.3780 - val_loss: 0.3414 - val_mean_absolute_error: 0.3414\n",
      "Epoch 88/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3768 - mean_absolute_error: 0.3768Epoch 00088: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 346us/step - loss: 0.3769 - mean_absolute_error: 0.3769 - val_loss: 0.3394 - val_mean_absolute_error: 0.3394\n",
      "Epoch 89/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3760 - mean_absolute_error: 0.3760Epoch 00089: val_loss improved from 0.33450 to 0.32628, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 78s 349us/step - loss: 0.3761 - mean_absolute_error: 0.3761 - val_loss: 0.3263 - val_mean_absolute_error: 0.3263\n",
      "Epoch 90/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3752 - mean_absolute_error: 0.3752Epoch 00090: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 351us/step - loss: 0.3752 - mean_absolute_error: 0.3752 - val_loss: 0.3275 - val_mean_absolute_error: 0.3275\n",
      "Epoch 91/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3738 - mean_absolute_error: 0.3738Epoch 00091: val_loss did not improve\n",
      "224000/224000 [==============================] - 80s 355us/step - loss: 0.3738 - mean_absolute_error: 0.3738 - val_loss: 0.3313 - val_mean_absolute_error: 0.3313\n",
      "Epoch 92/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3740 - mean_absolute_error: 0.3740Epoch 00092: val_loss improved from 0.32628 to 0.32343, saving model to myRNN_weights.h5\n",
      "224000/224000 [==============================] - 79s 352us/step - loss: 0.3740 - mean_absolute_error: 0.3740 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234\n",
      "Epoch 93/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3720 - mean_absolute_error: 0.3720Epoch 00093: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 347us/step - loss: 0.3720 - mean_absolute_error: 0.3720 - val_loss: 0.3330 - val_mean_absolute_error: 0.3330\n",
      "Epoch 94/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3710 - mean_absolute_error: 0.3710Epoch 00094: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 349us/step - loss: 0.3711 - mean_absolute_error: 0.3711 - val_loss: 0.3356 - val_mean_absolute_error: 0.3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3710 - mean_absolute_error: 0.3710- ETA: 3s - loss: 0.3709 - mean_absolute_error: 0.37 - ETA: 3s - losEpoch 00095: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 350us/step - loss: 0.3710 - mean_absolute_error: 0.3710 - val_loss: 0.3300 - val_mean_absolute_error: 0.3300\n",
      "Epoch 96/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3697 - mean_absolute_error: 0.3697- ETA: 0s - loss: 0.3695 - mean_absolute_erEpoch 00096: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 347us/step - loss: 0.3697 - mean_absolute_error: 0.3697 - val_loss: 0.3331 - val_mean_absolute_error: 0.3331\n",
      "Epoch 97/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3693 - mean_absolute_error: 0.3693Epoch 00097: val_loss did not improve\n",
      "224000/224000 [==============================] - 76s 341us/step - loss: 0.3693 - mean_absolute_error: 0.3693 - val_loss: 0.3246 - val_mean_absolute_error: 0.3246\n",
      "Epoch 98/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3679 - mean_absolute_error: 0.3679Epoch 00098: val_loss did not improve\n",
      "224000/224000 [==============================] - 77s 343us/step - loss: 0.3680 - mean_absolute_error: 0.3680 - val_loss: 0.3336 - val_mean_absolute_error: 0.3336\n",
      "Epoch 99/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3673 - mean_absolute_error: 0.3673- ETA: 0s - loss: 0.3674 - mean_absolute_erroEpoch 00099: val_loss did not improve\n",
      "224000/224000 [==============================] - 79s 351us/step - loss: 0.3673 - mean_absolute_error: 0.3673 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299\n",
      "Epoch 100/100\n",
      "223744/224000 [============================>.] - ETA: 0s - loss: 0.3657 - mean_absolute_error: 0.3657Epoch 00100: val_loss did not improve\n",
      "224000/224000 [==============================] - 78s 347us/step - loss: 0.3658 - mean_absolute_error: 0.3658 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 100\n",
    "\n",
    "myRNN_hist = myRNN.fit(X_train, y_train, epochs=nEpochs, batch_size=256,validation_split=0.20,\n",
    "                 callbacks=[earlyStop, myRNN_mChkPt],) # callbacks=[earlyStop, myRNN_mChkPt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d697833f98>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1,len(myRNN_hist.history['loss'])+1)\n",
    "\n",
    "plt.plot(epochs,myRNN_hist.history['loss'],label='training')\n",
    "plt.plot(epochs,myRNN_hist.history['val_loss'],label='validation')\n",
    "plt.xlabel('epochs',fontsize=14)\n",
    "plt.ylabel('MSE loss',fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.72788686,  -1.4395826 ,   1.1932702 ,   2.5045598 ,\n",
       "         -4.912249  ,   3.5406623 ],\n",
       "       [ -0.80760187,  -7.442497  ,  -8.630629  ,  -1.6996815 ,\n",
       "        -16.331194  , -18.601597  ],\n",
       "       [ -0.270205  ,  -0.46109116,   3.018742  ,  -0.48832706,\n",
       "         -0.94430906,   5.3533483 ],\n",
       "       ...,\n",
       "       [ -0.10353374,  -1.0832058 ,  -0.7272817 ,  -0.1281546 ,\n",
       "         -1.4839562 ,  -1.3016144 ],\n",
       "       [ -0.74823034,  -0.30717447,   2.1751206 ,  -2.113214  ,\n",
       "         -0.65330154,   5.5985956 ],\n",
       "       [  1.782252  ,   0.11208292,  -0.60954386,   2.6507761 ,\n",
       "          0.16549666,  -0.8945937 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=myRNN.predict(X_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_errs=(abs((results-y_test)/y_test)*100) # average error of 50%, so for vtx at 1mm, we get within 0.5mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#myRNN.load_weights('./myRNN_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24434., 21299., 16978., 12498.,  8902.,  6293.,  4632.,  3478.,\n",
       "         2573.,  2087.,  1622.,  1364.,  1148.,   927.,   823.,   669.]),\n",
       " array([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]),\n",
       " <a list of 16 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanerrs=percentage_errs.reshape(120000)# plot distribution of mean errs per jet\n",
    "\n",
    "plt.hist((meanerrs), bins=[0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80])\n",
    "# from what i see, the profile drops off but with a VERY long tail\n",
    "# about 65000/120000 vals less than 15% error (so more than half)\n",
    "# but 10000 have over 80% error (1/12)\n",
    "# problem also, for a jet we might nail down the x values very well but do badly with the z or y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_err_per_jet=np.mean(percentage_errs,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "couple of things, first the RNN looks like it predicts the same value for all cases. This might be because it uses the null tracks at the end of every single jet and just predicts off of those.\n",
    "Maybe should consider predicting values that are at least order unity, because mse is gonna be very small otherwise, so convert the vertices into different units (I dunno maybe millimeters or microns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1970"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_err_per_jet[mean_err_per_jet > 100.]) # 1970/20,000 jets mean err above 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   41,    51,    69, ..., 19958, 19966, 19987], dtype=int64),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(mean_err_per_jet > 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet=19987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.20304650395224"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_err_per_jet[jet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40814591, -0.02028324,  0.42077256, -2.32607675,  0.03202448,\n",
       "        2.27177641])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[jet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15107314, -0.0069042 ,  0.30029228, -2.2044108 , -0.23734276,\n",
       "        2.3917031 ], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[jet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=280000+np.where(mean_err_per_jet > 100.)[0]\n",
    "bad_phis=[]\n",
    "bad_thetas=[]\n",
    "\n",
    "for index in indices:\n",
    "    # extracts all the phi values of worst performing jets\n",
    "    bad_phis.append(abs(bjets_DF.iloc[index]['tracks'][0][2]))\n",
    "    bad_thetas.append(abs(bjets_DF.iloc[index]['tracks'][0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASr0lEQVR4nO3df5BdZX3H8c+nEe0PnQGbNUQkLoToDMSyyg6149Sh1TYRgmhHLZuODdZppGOYMNM/SFJHbGcIpBWFhlYbh0zijERoEYWAGyljBztTfyS4gSCgG1w1kl9Ca3R06CR++8eeTC+Hu9m797l3zznPvl8zd/ae55y755Nn7/3muc899xxHhAAAefm1qgMAAHqP4g4AGaK4A0CGKO4AkCGKOwBk6CVVB5Ck+fPnx+DgYNUxgEl79kz+vOiianMA09izZ89PImKg3bpaFPfBwUHt3r276hjAJHvyJ89J1JztH0y1jmkZAMgQxR0AMkRxB4AMUdwBIEO1+EAVqBXOt4QMMHIHgAxR3AEgQxR3oOyii/gCExqPOXeg7JFHqk4AJGPkDrQYXHf/C+63LgNNQnEHgAxR3AEgQxR3AMgQxR0AMsTRMkDJHRcuqzoCkIziDpRsWH5N1RGAZEzLAECGKO5AydJD41p6aLzqGEASpmWAkp3br5UkDV63s+IkQPcYuQNAhijuAJAhijsAZGja4m57q+0jtve1tN1pe6y4TdgeK9oHbf+yZd2n+xkeANBeJx+obpN0m6TPnmyIiD89ed/2zZJ+2rL9/ogY6lVAAMDMTVvcI+Jh24Pt1tm2pPdJ+sPexgIApEg9FPL3JR2OiO+1tJ1j+9uSjkn6SER8rd0Dba+WtFqSFi1alBgD6J0Vq26pOgKQLLW4j0ja0bJ8UNKiiHjW9kWSvmj7gog4Vn5gRGyRtEWShoeHudw8amPfmedVHQFI1vXRMrZfIulPJN15si0ino+IZ4v7eyTtl/S61JAAgJlJORTy7ZKejIgDJxtsD9ieV9w/V9ISSU+nRQRm18bRzdo4urnqGECSTg6F3CHpvyS93vYB2x8sVl2pF07JSNJbJT1qe6+kf5N0dUQ818vAQL+t3LtLK/fuqjoGkKSTo2VGpmi/qk3b3ZLuTo8FAEjBN1QBIEMUdwDIEMUdADJEcQeADHGxDqDksQWLq44AJKO4AyWXX3Vr1RGAZEzLAECGKO4AkCGKO1AysWmFJjatqDoGkITiDgAZorgDQIYo7gCQIYo7AGSI4g4AGaK4A0CG+IYqULJ+2ZqqIwDJKO5AyY6h5VVHAJIxLQMAGerkGqpbbR+xva+l7WO2f2x7rLhd2rJuve1x20/ZXtav4EC/jIyNamRstOoYQJJOpmW2SbpN0mdL7Z+MiI+3Ntg+X5MXzr5A0qsl/bvt10XEiR5kBWbFjbtuk8T0DJpt2pF7RDws6bkOf98Vkj4fEc9HxPcljUu6OCEfAKALKXPua2w/WkzbnFG0nSXpRy3bHCjaXsT2atu7be8+evRoQgwAQFm3xf1TkhZLGpJ0UNLNRbvbbBvtfkFEbImI4YgYHhgY6DIGAKCdrop7RByOiBMR8StJn9H/T70ckHR2y6avkfRMWkQAwEx1VdxtL2xZfLekk0fS3CvpStsvs32OpCWSvpkWEQAwU9MeLWN7h6RLJM23fUDS9ZIusT2kySmXCUkfkqSIeNz2XZK+I+m4pA9zpAwAzL5pi3tEjLRpvv0U298g6YaUUECVBq/bWXUEIBnfUAWADFHcASBDFHeg5L5ta3XftrVVxwCScFZIoOQNh/dXHQFIxsgdADJEcQeADFHcASBDFHcAyBDFHQAyxNEyQMkdF3IBMTQfxR0o2bD8mqojAMmYlgGADFHcgZKlh8a19NB41TGAJEzLACU7t18ribNDotkYuQNAhijuAJAhpmUAoA8G193/oraJmy6btf0zcgeADE1b3G1vtX3E9r6Wtn+w/aTtR23fY/v0on3Q9i9tjxW3T/czPACgvU5G7tskLS+1PShpaUT8jqTvSlrfsm5/RAwVt6t7ExMAMBOdXCD7YduDpbavtCx+XdJ7ehsLqM6KVbdUHQFI1osPVP9C0p0ty+fY/rakY5I+EhFf68E+gFmz78zzqo4AJEsq7rb/RtJxSZ8rmg5KWhQRz9q+SNIXbV8QEcfaPHa1pNWStGjRopQYAICSro+Wsb1K0gpJfxYRIUkR8XxEPFvc3yNpv6TXtXt8RGyJiOGIGB4YGOg2BtBzG0c3a+Po5qpjAEm6Ku62l0u6TtI7I+IXLe0DtucV98+VtETS070ICsyWlXt3aeXeXVXHAJJMOy1je4ekSyTNt31A0vWaPDrmZZIetC1JXy+OjHmrpL+zfVzSCUlXR8RzfcoOAJhCJ0fLjLRpvn2Kbe+WdHdqKABAGr6hCgAZorgDQIYo7gCQIc4KCZQ8tmBx1RGAZBR3oOTyq26tOgKQjGkZAMgQxR0AMkRxB0omNq3QxKYVVccAklDcASBDFHcAyBDFHQAyRHEHgAxlcZz74Lr7X7A8cdNlFSUBgHpg5A4AGcpi5A700vpla6qOACSjuAMlO4aWVx0BSMa0DABkiOIOlIyMjWpkbLTqGEASpmWAkht33SaJ6Rk027Qjd9tbbR+xva+l7ZW2H7T9veLnGS3r1tset/2U7WX9Cg4AmFon0zLbJJWHMOskPRQRSyQ9VCzL9vmSrpR0QfGYf7Y9r2dpAQAdmba4R8TDkp4rNV8haXtxf7ukd7W0fz4ino+I70sal3Rxj7ICADrU7QeqCyLioCQVP19VtJ8l6Uct2x0o2l7E9mrbu23vPnr0aJcxAADt9PpoGbdpi3YbRsSWiBiOiOGBgYEexwCAua3b4n7Y9kJJKn4eKdoPSDq7ZbvXSHqm+3gAgG50eyjkvZJWSbqp+PmllvY7bH9C0qslLZH0zdSQwGwavG5n1RGAZNMWd9s7JF0iab7tA5Ku12RRv8v2ByX9UNJ7JSkiHrd9l6TvSDou6cMRcaJP2QEAU5i2uEfEyBSr3jbF9jdIuiElFAAgDacfAEru27ZW921bW3UMIAmnHwBK3nB4f9URgGSM3AEgQxR3AMgQxR0AMkRxB4AMUdwBIEMcLQOU3HEhlyFA81HcgZINy6+pOgKQjGkZAMgQxR0oWXpoXEsPjVcdA0jCtAxQsnP7tZI4OySajZE7AGSI4g4AGaK4A0CGKO4AkCGKOwBkiOIOABnq+lBI26+XdGdL07mSPirpdEl/Kelo0b4hIh7oOiEwy1asuqXqCECyrot7RDwlaUiSbM+T9GNJ90j6gKRPRsTHe5IQmGX7zjyv6ghAsl59ieltkvZHxA9s9+hXAvUwuO7+FyxP3HRZRUmAzvVqzv1KSTtaltfYftT2VttntHuA7dW2d9veffTo0XabAJXYOLpZG0c3Vx0DSJJc3G2/VNI7Jf1r0fQpSYs1OWVzUNLN7R4XEVsiYjgihgcGBlJjAD2zcu8urdy7q+oYQJJejNzfIemRiDgsSRFxOCJORMSvJH1G0sU92AcAYAZ6UdxH1DIlY3thy7p3S9rXg30AAGYg6QNV278p6Y8kfail+e9tD0kKSROldUBtlD8oBXKSVNwj4heSfrvU9v6kRACAZHxDFQAyxMU6gJLHFiyuOgKQjOIOlFx+1a1VRwCSMS0DABmiuANAhijuQMnEphWa2LSi6hhAEoo7AGSI4g4AGaK4A0CGKO4AkCGKOwBkiOIOABniG6pAyfpla6qOACSjuAMlO4aWVx0BDVS3U0gzLQMAGaK4AyUjY6MaGRutOgaQhGkZoOTGXbdJYnoGzcbIHQAylHoN1QlJP5N0QtLxiBi2/UpJd0oa1OQ1VN8XEf+dFhMAMBO9GLn/QUQMRcRwsbxO0kMRsUTSQ8UyAGAW9WNa5gpJ24v72yW9qw/7AACcQuoHqiHpK7ZD0r9ExBZJCyLioCRFxEHbr2r3QNurJa2WpEWLFiXGAE6tbscgA/2WWtzfEhHPFAX8QdtPdvrA4j+CLZI0PDwciTmAWdPuP4qJmy6rIAkwtaTiHhHPFD+P2L5H0sWSDtteWIzaF0o60oOcwKwZvG5n1RGAZF3Pudv+LduvOHlf0h9L2ifpXkmris1WSfpSakgAwMykjNwXSLrH9snfc0dEjNr+lqS7bH9Q0g8lvTc9JgBgJrou7hHxtKQL27Q/K+ltKaGAKt23ba0k6fKrbq04CdA9Tj8AlLzh8P6qIwDJOP0AAGSI4g4AGaK4A0CGspxz50smAOY6Ru4AkKEsR+5AijsuXFZ1BCAZxR0o2bD8mqojAMmYlgGADFHcgZKlh8a19NB41TGAJEzLoLaqOupp5/ZrJ/fP2SHRYIzcASBDFHcAyBDTMkAP8MU51M2cLu68IAHkak4Xd6Cfmj54KOdvUnZQ3LvS9BctqsNzB7NlzhT3di8q5KHXf9sVq27p6e9DszX1P+SUC2Sfbfurtp+w/bjttUX7x2z/2PZYcbu0d3GB/tt35nnad+Z5VccAkqSM3I9L+uuIeMT2KyTtsf1gse6TEfHx9HjIQacjn05G4LwDAzqTcoHsg5IOFvd/ZvsJSWf1KlhdUEzmno2jmyVxAjFMrQl1oSdfYrI9KOmNkr5RNK2x/ajtrbbP6MU+gNmycu8urdy7q+oYQJLk4m775ZLulnRtRByT9ClJiyUNaXJkf/MUj1tte7ft3UePHk2NAQBokXS0jO3TNFnYPxcRX5CkiDjcsv4zktqefSkitkjaIknDw8ORkgNpmno0QK56+feoy9+2DsfM16UvZkvXxd22Jd0u6YmI+ERL+8JiPl6S3i1pX1rEuWcuPAmbMGc5l/D3yE/KyP0tkt4v6THbY0XbBkkjtockhaQJSR9KSjjLun2Sz4WCDNQRr732Uo6W+U9JbrPqge7j5I0nIZCul+8ycn7HMme+odp0dZizbCfHF8djCxbP6v4oVlPL7d8zmyjuFaviydvtl4Xq8h9Kv11+1a1VRwCSUdwBdG0uDwLqjuKeEd7C5osiOjO8FijumIG58oKZ2LRCEhfILpsrf/9cUNwBzDreifQfF8gGgAwxcgfmmH5PrzB9Uw8U94biBYTcngO5/XuqxrQMAGSI4g4AGWJaBihZv2xN1RGAZBR3oGTH0PKqIwDJKO59xAdEAKrCnDtQMjI2qpGx0apjAEkYuQMlN+66TRLTM2g2Ru4AkCGKOwBkiOIOABnqW3G3vdz2U7bHba/r134AAC/Wl+Jue56kf5L0DknnSxqxfX4/9gUAeLF+jdwvljQeEU9HxP9K+rykK/q0LwBASb8OhTxL0o9alg9I+t3WDWyvlrS6WPy57acS9jdf0k8SHl+lJmeXmp2/bXafvFNckanGsuv7Bukqvzf1PMdrp1rRr+LuNm3xgoWILZK29GRn9u6IGO7F75ptTc4uNTt/k7NLzc7f5OxSM/L3a1rmgKSzW5ZfI+mZPu0LAFDSr+L+LUlLbJ9j+6WSrpR0b5/2BQAo6cu0TEQct71G0i5J8yRtjYjH+7GvQk+mdyrS5OxSs/M3ObvU7PxNzi41IL8jYvqtAACNwjdUASBDFHcAyFBjivt0pzPwpH8s1j9q+01V5JxKB/kvsf1T22PF7aNV5GzH9lbbR2zvm2J9bfu+g+y17XdJsn227a/afsL247bXttmmlv3fYfba9r/tX7f9Tdt7i/x/22abWva9JCkian/T5Iey+yWdK+mlkvZKOr+0zaWSvqzJY+zfLOkbVeeeYf5LJO2sOusU+d8q6U2S9k2xvs59P1322vZ7kW+hpDcV918h6btNee53mL22/V/058uL+6dJ+oakNzeh7yOiMSP3Tk5ncIWkz8akr0s63fbC2Q46hUafjiEiHpb03Ck2qW3fd5C91iLiYEQ8Utz/maQnNPkN8Fa17P8Os9dW0Z8/LxZPK27lI1Bq2fdSc6Zl2p3OoPwk6WSbqnSa7feKt4Bftn3B7ETriTr3fSca0e+2ByW9UZMjyFa17/9TZJdq3P+259kek3RE0oMR0Zi+b8pl9qY9nUGH21Slk2yPSHptRPzc9qWSvihpSd+T9Uad+346jeh32y+XdLekayPiWHl1m4fUpv+nyV7r/o+IE5KGbJ8u6R7bSyOi9fOb2vZ9U0bunZzOoM6nPJg2W0QcO/kWMCIekHSa7fmzFzFJnfv+lJrQ77ZP02Rx/FxEfKHNJrXt/+myN6H/JSki/kfSf0gqX1i3tn3flOLeyekM7pX058Wn12+W9NOIODjbQacwbX7bZ9p2cf9iTf5tnp31pN2pc9+fUt37vch2u6QnIuITU2xWy/7vJHud+9/2QDFil+3fkPR2SU+WNqtl30sNmZaJKU5nYPvqYv2nJT2gyU+uxyX9QtIHqspb1mH+90j6K9vHJf1S0pVRfBxfNds7NHlUw3zbByRdr8kPl2rf9x1kr22/F94i6f2SHivmfiVpg6RFUu37v5Psde7/hZK2e/LiQ78m6a6I2NmUusPpBwAgQ02ZlgEAzADFHQAyRHEHgAxR3AEgQxR3AMgQxR0AMkRxB4AM/R9tO2TFs2N1MQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1d6c6dc3320>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(bad_phis,bins=np.linspace(0.,3.2,65))\n",
    "plt.axvline(x=np.pi/2, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(bad_thetas,bins=np.linspace(0.,3.2,65))\n",
    "plt.axvline(x=np.pi/2, color='r', linestyle='dashed', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4,\n",
       "       2.6, 2.8, 3. , 3.2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.,3.2,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so in 41, we actually only had one track from the secondary vertex, three from the tertiary\n",
    "# could this be fixed wih some sort of track ordering\n",
    "# perhaps the RNN expects secondarys before tertiarys\n",
    "# so it gets thrown when the number of sec and ter tracks is different.\n",
    "\n",
    "# in 51, the jet_phi was very close to -pi/2, this undoubtedly could lead to large errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0,z0,phi0,theta0,qoverp=1.3081643989711976e-05,-6.615451638936065e-06,-0.6557717081719833,1.800121842067036,5.373777313714585e-05\n",
    "\n",
    "jetphi,jettheta = -0.7666502947479463,1.8519400411980116\n",
    "\n",
    "x0=d0*np.cos(phi0)\n",
    "y0=d0*np.sin(phi0)\n",
    "trk_PoCA=[x0,y0,z0]\n",
    "dirvec=[100*np.sin(theta0)*np.cos(phi0), 100*np.sin(theta0)*np.sin(phi0), 100*np.cos(theta0)]\n",
    "trk_secondp=[0.,0.,0.]\n",
    "for i in range(len(trk_PoCA)):\n",
    "    trk_secondp[i]=PoCA[i]+dirvec[i]\n",
    "\n",
    "jetdir = [100*np.sin(jettheta)*np.cos(jetphi), 100*np.sin(jettheta)*np.sin(jetphi), 100*np.cos(jettheta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mathutils.geometry import intersect_line_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Vector((9.374803994433023e-06, -7.2125230872188695e-06, -6.322869012365118e-06)), Vector((9.028971362567972e-06, -8.696616532688495e-06, -3.620333473008941e-06)))\n"
     ]
    }
   ],
   "source": [
    "print(intersect_line_line(trk_PoCA,trk_secondp,[0,0,0],jetdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0368217982231362e-05, -7.976807967257435e-06, -6.615451638936065e-06] \n",
      " [0.771838238659556, -0.5938151977634709, -0.22732736406629356] \n",
      " [0, 0, 0] \n",
      " [0.6919610134810684, -0.666489968622366, -0.277454640523474]\n"
     ]
    }
   ],
   "source": [
    "print(trk_PoCA,\"\\n\",trk_secondp,\"\\n\",[0,0,0],\"\\n\",jetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
